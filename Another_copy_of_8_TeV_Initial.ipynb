{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rdalzell12/Bayesian-Analysis-of-the-Higgs-Boson-Discovery/blob/main/Another_copy_of_8_TeV_Initial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqprU3nFP_HB",
        "outputId": "19e5ed6b-8c5e-4221-c243-0ef6f3f79d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Connecting Colab to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing 8 TeV data\n",
        "\n",
        "!ls /content/drive/MyDrive/ULAB/complete_set_of_ATLAS_open_data_samples_July_2016.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoIkw7G7QE8Q",
        "outputId": "c99b04d2-8033-41cf-bf8f-a1a1fb1a4a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ULAB/complete_set_of_ATLAS_open_data_samples_July_2016.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzipping the file\n",
        "\n",
        "import os\n",
        "zip_path = '/content/drive/MyDrive/ULAB/complete_set_of_ATLAS_open_data_samples_July_2016.zip'\n",
        "extract_path = '/content/local_data/'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "!unzip \"$zip_path\" -d \"$extract_path\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WUGIBQls7OZ",
        "outputId": "5b1e81d0-d56f-4ca1-ba6b-4f97f9b6932b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/ULAB/complete_set_of_ATLAS_open_data_samples_July_2016.zip\n",
            "replace /content/local_data/.gitignore? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking what branches the zip file had\n",
        "import os\n",
        "os.listdir('/content/local_data')\n",
        "\n",
        "#The main file has three branches, as listed below - Data, MC, and .gitignore. Data and MC are branches containing relevant .root files,\n",
        "#while .gitignore is a file the computer needs to run - not important to us."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoGg4IvKwCvY",
        "outputId": "aad4f399-38b1-4c77-8162-918d23a51ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.gitignore', 'MC', 'Data']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking what is in the 'Data' branch\n",
        "import os\n",
        "os.listdir('/content/local_data/Data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79J7ZCfGw8wL",
        "outputId": "743690bb-dc6e-496c-e767-22bcf1c8ed75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DataEgamma.root', 'DataMuons.root']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Variable descriptions of Muon data\n",
        "\n",
        "!pip install uproot\n",
        "\n",
        "import uproot\n",
        "\n",
        "file_path = '/content/local_data/Data/DataMuons.root'\n",
        "\n",
        "try:\n",
        "    with uproot.open(file_path) as file:\n",
        "        if 'mini;1' in file:\n",
        "            tree = file['mini;1']\n",
        "            print(\"Description of variables (branches) in TTree 'mini;1':\\n\")\n",
        "            for branch_name in tree.keys():\n",
        "                try:\n",
        "                    branch_interpretation = tree[branch_name].interpretation.typename\n",
        "                    print(f\"  - {branch_name}: {branch_interpretation}\")\n",
        "                except Exception as branch_e:\n",
        "                    print(f\"  - {branch_name}: Could not determine type (Error: {branch_e})\")\n",
        "        else:\n",
        "            print(f\"Error: TTree 'mini;1' not found in {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error opening or processing the file: {e}\")"
      ],
      "metadata": {
        "id": "3S2icDgEANga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1904be-e88e-4ae9-e678-8f69d977c273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: uproot in /usr/local/lib/python3.12/dist-packages (5.7.1)\n",
            "Requirement already satisfied: awkward>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from uproot) (2.8.12)\n",
            "Requirement already satisfied: cramjam>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from uproot) (2.11.0)\n",
            "Requirement already satisfied: fsspec!=2025.7.0 in /usr/local/lib/python3.12/dist-packages (from uproot) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from uproot) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from uproot) (25.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from uproot) (3.6.0)\n",
            "Requirement already satisfied: awkward-cpp==51 in /usr/local/lib/python3.12/dist-packages (from awkward>=2.8.2->uproot) (51)\n",
            "Description of variables (branches) in TTree 'mini;1':\n",
            "\n",
            "  - runNumber: int32_t\n",
            "  - eventNumber: int32_t\n",
            "  - channelNumber: int32_t\n",
            "  - mcWeight: float\n",
            "  - pvxp_n: int32_t\n",
            "  - vxp_z: float\n",
            "  - scaleFactor_PILEUP: float\n",
            "  - scaleFactor_ELE: float\n",
            "  - scaleFactor_MUON: float\n",
            "  - scaleFactor_BTAG: float\n",
            "  - scaleFactor_TRIGGER: float\n",
            "  - scaleFactor_JVFSF: float\n",
            "  - scaleFactor_ZVERTEX: float\n",
            "  - trigE: bool\n",
            "  - trigM: bool\n",
            "  - passGRL: bool\n",
            "  - hasGoodVertex: bool\n",
            "  - lep_n: uint32_t\n",
            "  - lep_truthMatched: bool[]\n",
            "  - lep_trigMatched: uint16_t[]\n",
            "  - lep_pt: float[]\n",
            "  - lep_eta: float[]\n",
            "  - lep_phi: float[]\n",
            "  - lep_E: float[]\n",
            "  - lep_z0: float[]\n",
            "  - lep_charge: float[]\n",
            "  - lep_type: uint32_t[]\n",
            "  - lep_flag: uint32_t[]\n",
            "  - lep_ptcone30: float[]\n",
            "  - lep_etcone20: float[]\n",
            "  - lep_trackd0pvunbiased: float[]\n",
            "  - lep_tracksigd0pvunbiased: float[]\n",
            "  - met_et: float\n",
            "  - met_phi: float\n",
            "  - jet_n: uint32_t\n",
            "  - alljet_n: uint32_t\n",
            "  - jet_pt: float[]\n",
            "  - jet_eta: float[]\n",
            "  - jet_phi: float[]\n",
            "  - jet_E: float[]\n",
            "  - jet_m: float[]\n",
            "  - jet_jvf: float[]\n",
            "  - jet_trueflav: int32_t[]\n",
            "  - jet_truthMatched: int32_t[]\n",
            "  - jet_SV0: float[]\n",
            "  - jet_MV1: float[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uproot\n",
        "import awkward as ak\n",
        "\n",
        "file_path = '/content/local_data/Data/DataMuons.root'\n",
        "\n",
        "branches_to_extract = [\n",
        "    'lep_type'\n",
        "]\n",
        "\n",
        "#Seeing the shape (number of leptons/event) of the data - this shape should be the same for every file, as each file is a different set of data describing the same set of events,\n",
        "#so this cell only needs to be run once - takes forever to run\n",
        "\n",
        "try:\n",
        "    with uproot.open(file_path) as file:\n",
        "        tree = file['mini;1']\n",
        "        extracted_data = tree.arrays(branches_to_extract, library='ak')\n",
        "\n",
        "    row_lengths = [len(row) for row in extracted_data['lep_type']]\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error processing data: {e}\")\n",
        "\n",
        "one_lep = row_lengths.count(1)\n",
        "two_lep = row_lengths.count(2)\n",
        "three_lep = row_lengths.count(3)\n",
        "four_lep = row_lengths.count(4)\n",
        "five_lep = row_lengths.count(5)\n",
        "\n",
        "print(one_lep, two_lep, three_lep, four_lep, five_lep)\n",
        "\n",
        "#Lepton count frequency:\n",
        "#One lepton: 6374629 events\n",
        "#Two leptons: 647126\n",
        "#Three leptoons: 6215\n",
        "#Four leptons: 111\n",
        "#Five leptons: 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXP3uibGpye7",
        "outputId": "7a6fa25f-78ab-4393-dd61-d1e6e92b92a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6374629 647126 6215 111 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the indices of the events where four leptons were observed\n",
        "def get_indices_lc(my_list, target_value):\n",
        "    return [i for i, x in enumerate(my_list) if x == target_value]\n",
        "four_leps = get_indices_lc(row_lengths, 4)\n",
        "print(four_leps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57hKtkc1XNrj",
        "outputId": "bc8fe11d-d90b-4b17-f01e-cdf840af56a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[34389, 43437, 121558, 157944, 177527, 195062, 257924, 301500, 443960, 507361, 642379, 743820, 829867, 845981, 902863, 911298, 1014746, 1186734, 1188124, 1219039, 1331440, 1402560, 1404321, 1426778, 1440851, 1496630, 1565998, 1619915, 1765846, 2014571, 2164503, 2355723, 2417509, 2512054, 2584745, 2651872, 2829777, 2835427, 2856104, 2896298, 2977326, 2978741, 3186580, 3228734, 3256120, 3283872, 3376833, 3394641, 3499880, 3502292, 3564816, 3564974, 3611708, 3619444, 3689319, 4025043, 4028218, 4035525, 4138999, 4289323, 4296621, 4306744, 4339234, 4348409, 4353526, 4373581, 4400993, 4430147, 4441560, 4492788, 4552578, 4595009, 4620502, 4652992, 4664280, 4746014, 4766538, 5016903, 5071256, 5141389, 5346668, 5413264, 5490532, 5533557, 5563519, 5571477, 5656866, 5711158, 5716851, 5740277, 5843607, 5926121, 5943483, 5987501, 6022392, 6205081, 6384116, 6393556, 6397451, 6435272, 6527004, 6621388, 6699498, 6714255, 6787477, 6854117, 6905532, 6915570, 6916495, 6996668, 7024905]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code to extract all modules\n",
        "import numpy as np\n",
        "import awkward as ak\n",
        "import uproot\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = '/content/local_data/Data/DataMuons.root'\n",
        "\n",
        "branches_to_extract = [\n",
        "    'lep_pt', 'lep_n', 'lep_truthMatched','lep_trigMatched', 'lep_type', 'lep_charge', 'lep_flag', 'lep_eta', 'lep_phi', 'lep_E', 'lep_z0', 'lep_ptcone30', 'lep_etcone20', 'lep_trackd0pvunbiased', 'lep_tracksigd0pvunbiased', 'met_et', 'met_phi', 'jet_n', 'alljet_n', 'jet_pt', 'jet_eta', 'jet_phi', 'jet_E', 'jet_m', 'jet_jvf', 'jet_trueflav', 'jet_truthMatched', 'jet_SV0', 'jet_MV1'\n",
        "]\n",
        "\n",
        "try:\n",
        "    with uproot.open(file_path) as file:\n",
        "        tree = file['mini;1']\n",
        "        extracted_data = tree.arrays(branches_to_extract, library='ak')\n",
        "\n",
        "    num_events = len(extracted_data)\n",
        "    fixed_lepton_count = 4\n",
        "    processed_data_np = {}\n",
        "    print(num_events)\n",
        "\n",
        "    for branch_name in branches_to_extract:\n",
        "        ak_array = extracted_data[branch_name]\n",
        "        is_jagged_array = ak_array.ndim > 1\n",
        "\n",
        "        if is_jagged_array:\n",
        "            padded_ak_array = ak.fill_none(ak.pad_none(ak_array, fixed_lepton_count, clip=True), 0)\n",
        "            processed_data_np[branch_name] = ak.to_numpy(padded_ak_array)\n",
        "        else:\n",
        "            repeated_scalar = np.repeat(ak.to_numpy(ak_array), fixed_lepton_count).reshape(num_events, fixed_lepton_count)\n",
        "            processed_data_np[branch_name] = repeated_scalar\n",
        "\n",
        "    print(processed_data_np['lep_pt'][:10])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error processing data: {e}\")\n",
        "\n",
        "'''#Making the awkward array into a list and then a dataframe\n",
        "python_list = ak.to_list(processed_data_np)\n",
        "df = pd.DataFrame(python_list)\n",
        "\n",
        "# Flatten the 'lep_pt' data for plotting\n",
        "lep_pt_flat = df['lep_pt'].apply(lambda x: x[0])'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "w4b-nbpviVn4",
        "outputId": "cc95ad28-f7d2-4be3-d06c-fd836207ffb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'awkward'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1225737715.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mawkward\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muproot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'awkward'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install uproot\n",
        "\n",
        "#Trying to make a dataframe with only values in Anson and Colton's existing dataframe\n",
        "import numpy as np\n",
        "import awkward as ak\n",
        "import uproot\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = '/content/local_data/Data/DataMuons.root'\n",
        "\n",
        "branches_to_extract = [\n",
        "    'lep_charge', 'lep_pt', 'lep_eta','lep_phi', 'lep_E', 'lep_type', 'lep. isTightlD', 'lep_ptcone30', 'lep_ptcone20', 'runNumber', 'met_et'\n",
        "]\n",
        "try:\n",
        "    with uproot.open(file_path) as file:\n",
        "        tree = file['mini;1']\n",
        "        extracted_data = tree.arrays(branches_to_extract, library='ak')\n",
        "\n",
        "    num_events = len(extracted_data)\n",
        "    fixed_lepton_count = 4\n",
        "    processed_data_np = {}\n",
        "    print(num_events)\n",
        "\n",
        "    for branch_name in branches_to_extract:\n",
        "        ak_array = extracted_data[branch_name]\n",
        "        is_jagged_array = ak_array.ndim > 1\n",
        "\n",
        "        if is_jagged_array:\n",
        "            padded_ak_array = ak.fill_none(ak.pad_none(ak_array, fixed_lepton_count, clip=True), 0)\n",
        "            processed_data_np[branch_name] = ak.to_numpy(padded_ak_array)\n",
        "        else:\n",
        "            repeated_scalar = np.repeat(ak.to_numpy(ak_array), fixed_lepton_count).reshape(num_events, fixed_lepton_count)\n",
        "            processed_data_np[branch_name] = repeated_scalar\n",
        "\n",
        "    print(processed_data_np[:][:10])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error processing data: {e}\")\n",
        "\n",
        "'''#Making the awkward array into a list and then a dataframe\n",
        "python_list = ak.to_list(processed_data_np)\n",
        "df = pd.DataFrame(python_list)\n",
        "\n",
        "# Flatten the 'lep_pt' data for plotting\n",
        "lep_pt_flat = df['lep_pt'].apply(lambda x: x[0])'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "gZE9y9IThvje",
        "outputId": "7b884fc5-5437-4e9f-d2dc-a7219b51417a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uproot\n",
            "  Downloading uproot-5.7.1-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting awkward>=2.8.2 (from uproot)\n",
            "  Downloading awkward-2.8.12-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: cramjam>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from uproot) (2.11.0)\n",
            "Requirement already satisfied: fsspec!=2025.7.0 in /usr/local/lib/python3.12/dist-packages (from uproot) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from uproot) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from uproot) (25.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from uproot) (3.6.0)\n",
            "Collecting awkward-cpp==51 (from awkward>=2.8.2->uproot)\n",
            "  Downloading awkward_cpp-51-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.2 kB)\n",
            "Downloading uproot-5.7.1-py3-none-any.whl (393 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.8/393.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading awkward-2.8.12-py3-none-any.whl (913 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.7/913.7 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading awkward_cpp-51-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (656 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.7/656.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: awkward-cpp, awkward, uproot\n",
            "Successfully installed awkward-2.8.12 awkward-cpp-51 uproot-5.7.1\n",
            "Error processing data: [Errno 2] No such file or directory: '/content/local_data/Data/DataMuons.root'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"#Making the awkward array into a list and then a dataframe\\npython_list = ak.to_list(processed_data_np)\\ndf = pd.DataFrame(python_list)\\n\\n# Flatten the 'lep_pt' data for plotting\\nlep_pt_flat = df['lep_pt'].apply(lambda x: x[0])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}